# ğŸ™ï¸ Deepfake Detection Using Spectrogram Analysis

## ğŸ“– Overview
This repository contains all core scripts and utilities for **deepfake detection research** using **spectrogram analysis** and **CNN-based models**.  
It provides a **modular and reproducible pipeline** to process audio data, generate spectrograms, simulate laundering attacks, and train/evaluate deep learning models.

The goal of this codebase is to create a **scalable, attack-resilient workflow** that enables reproducible experiments on benchmark datasets.

---

## ğŸ“‚ Folder Structure

scripts/
â”‚
â”œâ”€â”€ generation_scripts/                # Dataset generation & preprocessing utilities
â”‚   â”œâ”€â”€ csv_generation/
â”‚   â”‚   â”œâ”€â”€ gen_csv.py                 # Generate CSV files with spectrogram paths + labels
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”‚
â”‚   â”œâ”€â”€ dataset_builder/
â”‚   â”‚   â”œâ”€â”€ balanced_dataset_builder.py# Build balanced dataset (original vs fake samples)
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”‚
â”‚   â”œâ”€â”€ laundering_attack_implementation/
â”‚   â”‚   â”œâ”€â”€ laundering.py              # Implements laundering attacks (noise, reverb, resample, etc.)
â”‚   â”‚   â”œâ”€â”€ stochastic_attack.py       # Automates attack pipelines across datasets
â”‚   â”‚   â”œâ”€â”€ noises/                    # Background noise samples
â”‚   â”‚   â”‚   â”œâ”€â”€ babble.wav
â”‚   â”‚   â”‚   â”œâ”€â”€ cafe.wav
â”‚   â”‚   â”‚   â”œâ”€â”€ street.wav
â”‚   â”‚   â”‚   â”œâ”€â”€ volvo.wav
â”‚   â”‚   â”‚   â””â”€â”€ white.wav
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”‚
â”‚   â””â”€â”€ spectrogram_generation/
â”‚       â”œâ”€â”€ gen_spectra.py             # Convert audio to spectrogram images
â”‚       â””â”€â”€ README.md
â”‚
â””â”€â”€ model_training_and_testing/
â”œâ”€â”€ deepfake_detection_cnn_resnet_18.py   # Train ResNet-18 CNN on spectrogram dataset
â”œâ”€â”€ evaluate_resnet18_deepfake.py         # Evaluate trained model (metrics, confusion matrix)
â””â”€â”€ README.md

---

## âš¡ Workflow Pipeline

### 1ï¸âƒ£ Data Preparation
- Collect raw audio files (`.wav`) from dataset(s).  
- Build a balanced dataset:
```bash```
python scripts/generation_scripts/dataset_builder/balanced_dataset_builder.py --input ./audio --output ./balanced_data

	â€¢	Generate CSV metadata:

python scripts/generation_scripts/csv_generation/gen_csv.py --input ./spectrograms --output metadata.csv


â¸»

2ï¸âƒ£ Laundering Attack Simulation (optional, for robustness testing)
	â€¢	Apply predefined attacks (e.g., reverberation, resampling, compression, noise):

python scripts/generation_scripts/laundering_attack_implementation/laundering.py --input ./audio --attack reverberation

	â€¢	Run stochastic (randomized) attacks:

python scripts/generation_scripts/laundering_attack_implementation/stochastic_attack.py --input ./audio --output ./attacked_data


â¸»

3ï¸âƒ£ Spectrogram Generation

Convert .wav audio to spectrogram PNGs:

python scripts/generation_scripts/spectrogram_generation/gen_spectra.py --input ./balanced_data --output ./spectrograms


â¸»

4ï¸âƒ£ Model Training

Train a ResNet-18 CNN:

python scripts/model_training_and_testing/deepfake_detection_cnn_resnet_18.py \
    --data ./spectrograms \
    --epochs 30 \
    --batch_size 32 \
    --lr 0.001

Includes:
	â€¢	Train/Validation/Test split (70/15/15).
	â€¢	Data augmentation (random crops, flips).
	â€¢	Early stopping & checkpoint saving.

â¸»

5ï¸âƒ£ Model Evaluation

Evaluate trained model:

python scripts/model_training_and_testing/evaluate_resnet18_deepfake.py \
    --model ./checkpoints/best_model.pth \
    --data ./spectrograms/test


â¸»

Requirements

Create a requirements.txt:

torch
torchvision
librosa
soundfile
audiomentations
pyroomacoustics
scipy
numpy
pandas
matplotlib
scikit-learn
tqdm
seaborn
ffmpeg-python

Install dependencies:

pip install -r requirements.txt


â¸»

Example Experiment Workflow
	1.	Prepare balanced dataset:

python balanced_dataset_builder.py --input ./raw_audio --output ./balanced_data

	2.	Apply laundering attacks:

python laundering.py --input ./balanced_data --attack resample_22050

	3.	Generate spectrograms:

python gen_spectra.py --input ./balanced_data --output ./spectrograms

	4.	Train ResNet-18:

python deepfake_detection_cnn_resnet_18.py --data ./spectrograms

	5.	Evaluate:

python evaluate_resnet18_deepfake.py --model ./checkpoints/best_model.pth


â¸»

Outputs
	â€¢	Spectrogram PNGs (preprocessed features).
	â€¢	CSV metadata with file paths + labels.
	â€¢	Augmented datasets (with attacks applied).
	â€¢	Trained CNN models (.pth checkpoints).
	â€¢	Evaluation reports (confusion matrix, classification report).

â¸»

Key Features
	â€¢	Modular pipeline for reproducible experiments.
	â€¢	Implements laundering attacks (noise, reverb, resampling, compression).
	â€¢	Spectrogram generation with configurable parameters.
	â€¢	Deep learning training using CNN (ResNet-18) with transfer learning.
	â€¢	Evaluation metrics: Accuracy, Precision, Recall, F1-score, Confusion Matrix.

â¸»

Contribution Guidelines
	â€¢	Follow naming conventions (snake_case for Python scripts).
	â€¢	Add new attacks or models under relevant subfolders.
	â€¢	Use README.md in subfolders for script-specific instructions.

â¸»

Citation

If you use this codebase for your research, please cite:

@thesis{2025deepfake_detection_spectrogram_analysis,
  title={Efficient Audio Deepfake Detection Using Spectrogram Filtering and Thresholding},
  author={Atharva Pore and Aishwarya Dekhane},
  year={2025},
  institution={University of Michigan-Dearborn}
}

---
